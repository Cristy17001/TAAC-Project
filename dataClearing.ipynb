{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModel\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# directory = '.\\\\goodreads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender_dict = {\n",
    "#     \"children\": [],\n",
    "#     \"comics_graphics\": [],\n",
    "#     \"fantasy_paranormal\": [],\n",
    "#     \"history\": [],\n",
    "#     \"young_adult\": [],\n",
    "# }\n",
    "\n",
    "# order = ['children', 'comics_graphics', 'fantasy_paranormal', 'history_biography', 'mystery_thriller_crime', 'poetry', 'romance', 'young_adult']\n",
    "# final_df = pd.DataFrame()\n",
    "\n",
    "# index = -1\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.json'):\n",
    "#         index+=1\n",
    "#         filename = os.path.join(directory, filename)\n",
    "#         with open(filename, 'r') as file:\n",
    "#             counter = 0\n",
    "#             jsonData = []\n",
    "#             for line in file:\n",
    "#                 counter+=1\n",
    "#                 jsonData.append(json.loads(line))\n",
    "#                 if (counter == 5000): break\n",
    "                \n",
    "#             jsonDataFrame = pd.DataFrame(jsonData)\n",
    "#             jsonDataFrame[\"type\"] = order[index]\n",
    "#             final_df = pd.concat([final_df, jsonDataFrame], axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "# print(final_df)\n",
    "# final_df.to_csv('filtered_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristiano\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model and tokenizer\n",
    "OPT = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Specify the file path of the CSV file\n",
    "# csv_file = 'filtered_data.csv'\n",
    "\n",
    "# # # Read the CSV file and create a dataframe, parsing the dates\n",
    "# df = pd.read_csv(csv_file, parse_dates=[\"date_added\", \"date_updated\", \"read_at\", \"started_at\"])\n",
    "\n",
    "# # df = pd.read_csv(csv_file)\n",
    "# # df.to_csv('filtered_data.csv', index=False)\n",
    "\n",
    "# # Converting dates to ordinal\n",
    "# def dateToOrdinal(x):\n",
    "#     if (pd.isna(x)): return pd.NA\n",
    "#     return x.toordinal()\n",
    "\n",
    "# # def treatMissingDate(row, column):\n",
    "# #     copy_df = df.copy()\n",
    "# #     if (pd.isna(row[column])):\n",
    "# #         selected_rows = df[(df['type'] == row[\"type\"]) & df[column].notna()]\n",
    "# #         mean = selected_rows[column].mean()\n",
    "# #         copy_df[row][column] = mean\n",
    "# #         return copy_df[row]\n",
    "    \n",
    "# #     return row\n",
    "\n",
    "# df[\"date_added\"] = df[\"date_added\"].apply(dateToOrdinal)\n",
    "# df[\"date_updated\"] = df[\"date_updated\"].apply(dateToOrdinal)\n",
    "\n",
    "# df[\"read_at\"] = df[\"read_at\"].apply(dateToOrdinal)\n",
    "# df[\"read_at\"] = df.apply(lambda row: df[df[\"type\"] == row[\"type\"]][\"read_at\"].mean() if round(pd.isna(row[\"read_at\"]), 1) else row[\"read_at\"], axis=1)\n",
    "\n",
    "# df[\"started_at\"] = df[\"started_at\"].apply(dateToOrdinal)\n",
    "# df[\"started_at\"] = df.apply(lambda row: df[df[\"type\"] == row[\"type\"]][\"started_at\"].mean() if round(pd.isna(row[\"started_at\"]), 1) else row[\"started_at\"], axis=1)\n",
    "\n",
    "# # Save the modified dataframe back to the CSV file\n",
    "# df.to_csv('filtered_data_.csv', index=False)\n",
    "\n",
    "# Print the dataframe\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"read_at\"] = df[\"read_at\"].round(1)\n",
    "# df[\"started_at\"] = df[\"started_at\"].round(1)\n",
    "\n",
    "# df.to_csv('filtered_data_.csv', index=False)\n",
    "df = pd.read_csv('filtered_data_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the review_text column using the tokenizer to get the input_ids and attention_mask and tensorize the output using PyTorch\n",
    "# df[\"review_text\"] = df[\"review_text\"].apply(lambda x: tokenizer(str(x), return_tensors=\"pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['type'] = le.fit_transform(df['type'])\n",
    "# df.drop(columns=[\"user_id\", \"review_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('filtered_data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
